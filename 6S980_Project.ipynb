{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3_IvSlv8esf"
      },
      "source": [
        "## Directory Structure\n",
        "PLEASE make sure your directory looks like this:\n",
        "- root_dir\n",
        "    - pixel-nerf (clone/pull from github)\n",
        "    - adaptive-volume-rendering (clone/pull from github)\n",
        "        - 6S980_Project.ipynb\n",
        "    - scene-representation-networks (clone/pull from github)\n",
        "    - data\n",
        "    - checkpoints\n",
        "    - ......\n",
        "    \n",
        "Then set your pwd to root_dir\n",
        "\n",
        "## Relevant Repos\n",
        "\n",
        "- PixelNeRF repo: https://github.com/sxyu/pixel-nerf\n",
        "\n",
        "- SRN repo: https://github.com/vsitzmann/scene-representation-networks\n",
        "\n",
        "- SRN raymarcher algorithm: https://github.com/vsitzmann/scene-representation-networks/blob/master/custom_layers.py\n",
        "\n",
        "## Data\n",
        "\n",
        "- Currently using cars dataset from SRN\n",
        "\n",
        "## What we did\n",
        "\n",
        "- Built a running pixelnerf model, tested it on single car overfitting (convergence much slower)\n",
        "\n",
        "\n",
        "## Questions\n",
        "\n",
        "- LSTM should interact with features (output from eocoder) before finally feed into nerf right?\n",
        "- PixelNeRF converges much slower. Is sl<32 even feasible? Is comparing metrics like PSNR valid before convergence? Or should we compare something like convergence speed?\n",
        "- PixelNeRF currently does: evenly coarse sampling - fine sampling via importance weights - fine sampling around expected depth. With adaptive procedure, what is a fair comparison?\n",
        "\n",
        "## TODOs\n",
        "- First attempt: let LSTM interact with the features, do 10 steps, then directly output a color\n",
        "- Second attempt: sample points around the final location and do volume integral\n",
        "- Check camera convention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/yankesong/Documents/YankeSong/Harvard Textbook/MIT 6.S980/Project\n",
            "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 1)) (1.13.0)\n",
            "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: pretrainedmodels in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 3)) (0.7.4)\n",
            "Requirement already satisfied: pyhocon in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 4)) (0.3.59)\n",
            "Requirement already satisfied: imageio in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 5)) (2.22.4)\n",
            "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: imageio-ffmpeg in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 7)) (0.4.7)\n",
            "Requirement already satisfied: tensorboard in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 8)) (2.11.0)\n",
            "Requirement already satisfied: dotmap in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 9)) (1.3.30)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 10)) (1.23.4)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 11)) (1.9.3)\n",
            "Requirement already satisfied: scikit-image in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 12)) (0.19.3)\n",
            "Requirement already satisfied: ipdb in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 13)) (0.13.9)\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 14)) (3.6.2)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 15)) (4.64.1)\n",
            "Requirement already satisfied: lpips in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 16)) (0.1.4)\n",
            "Requirement already satisfied: einops in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 17)) (0.6.0)\n",
            "Requirement already satisfied: gdown in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 18)) (4.5.3)\n",
            "Requirement already satisfied: h5py in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r adaptive-volume-rendering/requirements.txt (line 19)) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->-r adaptive-volume-rendering/requirements.txt (line 1)) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torchvision->-r adaptive-volume-rendering/requirements.txt (line 2)) (9.3.0)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torchvision->-r adaptive-volume-rendering/requirements.txt (line 2)) (2.28.1)\n",
            "Requirement already satisfied: munch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pretrainedmodels->-r adaptive-volume-rendering/requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: pyparsing~=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyhocon->-r adaptive-volume-rendering/requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (1.50.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (0.38.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-image->-r adaptive-volume-rendering/requirements.txt (line 12)) (2022.10.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-image->-r adaptive-volume-rendering/requirements.txt (line 12)) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-image->-r adaptive-volume-rendering/requirements.txt (line 12)) (2.8.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from scikit-image->-r adaptive-volume-rendering/requirements.txt (line 12)) (21.3)\n",
            "Requirement already satisfied: ipython>=7.17.0 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (8.5.0)\n",
            "Requirement already satisfied: toml>=0.10.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.10.2)\n",
            "Requirement already satisfied: decorator in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (5.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->-r adaptive-volume-rendering/requirements.txt (line 14)) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->-r adaptive-volume-rendering/requirements.txt (line 14)) (1.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r adaptive-volume-rendering/requirements.txt (line 14)) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->-r adaptive-volume-rendering/requirements.txt (line 14)) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->-r adaptive-volume-rendering/requirements.txt (line 14)) (1.4.4)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from gdown->-r adaptive-volume-rendering/requirements.txt (line 18)) (3.8.0)\n",
            "Requirement already satisfied: six in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from gdown->-r adaptive-volume-rendering/requirements.txt (line 18)) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from gdown->-r adaptive-volume-rendering/requirements.txt (line 18)) (4.11.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (2.13.0)\n",
            "Requirement already satisfied: traitlets>=5 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (5.4.0)\n",
            "Requirement already satisfied: backcall in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (4.8.0)\n",
            "Requirement already satisfied: appnope in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.1.3)\n",
            "Requirement already satisfied: stack-data in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.5.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.18.1)\n",
            "Requirement already satisfied: matplotlib-inline in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (3.0.31)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (5.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torchvision->-r adaptive-volume-rendering/requirements.txt (line 2)) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torchvision->-r adaptive-volume-rendering/requirements.txt (line 2)) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torchvision->-r adaptive-volume-rendering/requirements.txt (line 2)) (1.26.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torchvision->-r adaptive-volume-rendering/requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (2.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from beautifulsoup4->gdown->-r adaptive-volume-rendering/requirements.txt (line 18)) (2.3.2.post1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torchvision->-r adaptive-volume-rendering/requirements.txt (line 2)) (1.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from jedi>=0.16->ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r adaptive-volume-rendering/requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: pure-eval in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (0.2.2)\n",
            "Requirement already satisfied: asttokens in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (2.0.8)\n",
            "Requirement already satisfied: executing in /Users/yankesong/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython>=7.17.0->ipdb->-r adaptive-volume-rendering/requirements.txt (line 13)) (1.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installed Torch version: 1.13.0\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "root_dir = \"/Users/yankesong/Documents/YankeSong/Harvard Textbook/MIT 6.S980/Project/\"       # This is the only thing you need to change.\n",
        "%cd \"/Users/yankesong/Documents/YankeSong/Harvard Textbook/MIT 6.S980/Project/\"\n",
        "\n",
        "# root_dir = \"/Users/jameszli/desktop/MIT/6.S980/\"       # This is the only thing you need to change.\n",
        "# %cd \"/Users/jameszli/desktop/MIT/6.S980/\"\n",
        "\n",
        "# Install everything\n",
        "%pip install -r adaptive-volume-rendering/requirements.txt\n",
        "\n",
        "# Import everything\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, f\"{root_dir}/scene-representation-networks/\")\n",
        "sys.path.insert(0, f\"{root_dir}/pixel-nerf/src/\")\n",
        "sys.path.insert(0, f\"{root_dir}/adaptive-volume-rendering/\")\n",
        "\n",
        "from dataset import *\n",
        "from models import *\n",
        "from renderers import *\n",
        "from trains import *\n",
        "from utils import *\n",
        "from model import make_model, loss\n",
        "\n",
        "print(f\"Installed Torch version: {torch.__version__}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9h59cKEDM6O"
      },
      "source": [
        "## Setup & Load Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "wcct4u0iHywz",
        "outputId": "124f87f7-c70a-4612-9d70-87a1af0cb7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: data: File exists\n",
            "mkdir: checkpoints: File exists\n"
          ]
        }
      ],
      "source": [
        "# Download data and weights\n",
        "\n",
        "# Make a new directory\n",
        "!mkdir data\n",
        "!mkdir checkpoints\n",
        "\n",
        "# Download Test Dataset\n",
        "if not os.path.exists(f\"{root_dir}data/cars_train.hdf5\"):\n",
        "    # Download SRNs-cars dataset\n",
        "    gdown.download(\"https://drive.google.com/uc?id={}\".format(\"1SBjlsizq0sFNkCZxMQh-pNRi0HyFozKb\"),f\"{root_dir}data/cars_train.hdf5\")\n",
        "\n",
        "\n",
        "## Download pretrained weights from PixelNeRF\n",
        "if not os.path.exists(f\"{root_dir}checkpoints/pixel_nerf_weights.zip\"):\n",
        "  gdown.download(\"https://drive.google.com/uc?id={}\".format(\"1UO_rL201guN6euoWkCOn-XpqR2e8o6ju\"),f\"{root_dir}checkpoints/pixel_nerf_weights.zip\")\n",
        "  !unzip checkpoints/pixel_nerf_weights.zip -d checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # View test image\n",
        "# sl = 128\n",
        "# dataset = SRNsCars(root_dir,img_sidelength=sl)\n",
        "# mi = next(iter(dataset))\n",
        "\n",
        "# rgb = mi['images'].reshape(sl, sl, 3)\n",
        "\n",
        "# plt.imshow(rgb)\n",
        "# plt.show()\n",
        "\n",
        "# print(\"Cam2world \", mi['cam2world'])\n",
        "# print(\"Intrinsics \", mi['intrinsics'])\n",
        "# print(\"Pixel coords\", mi['x_pix'], mi['x_pix'].max())\n",
        "# print(\"Scene idx\", mi['idx'])\n",
        "\n",
        "\n",
        "# # Below are for pixelnerf convention\n",
        "# key = \"4e384de22a760ef72e877e82c90c24d\"\n",
        "\n",
        "\n",
        "# for i in range(250):\n",
        "#     observation_idx = list(str(100000 + i))\n",
        "#     observation_idx[0] = '0'\n",
        "#     observation_idx = \"\".join(observation_idx)\n",
        "#     pose_path = f\"{root_dir}data/cars_train/{key}/pose/{observation_idx}.txt\"\n",
        "#     pose = torch.from_numpy(\n",
        "#                 np.loadtxt(pose_path, dtype=np.float32).reshape(4, 4)\n",
        "#             )\n",
        "#     #print(abs(pose[0,0] - mi['cam2world'][0,0]))\n",
        "#     if abs(pose[0,0] - mi['cam2world'][0,0]) < 2e-2:\n",
        "#         print(f'found it! observation number {observation_idx}')\n",
        "#         print(pose)\n",
        "\n",
        "#         rgb_path = f\"{root_dir}data/cars_train/{key}/rgb/{observation_idx}.png\"\n",
        "#         img = imageio.imread(rgb_path)[..., :3]\n",
        "#         to_tensor = transforms.ToTensor()\n",
        "#         img_tensor = to_tensor(img)\n",
        "#         plt.imshow(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking axis alignment\n",
        "# sl = 4\n",
        "# print(get_opencv_pixel_coordinates(sl,sl))\n",
        "# Y, X = torch.meshgrid(\n",
        "#         torch.arange(sl, dtype=torch.float32),\n",
        "#         torch.arange(sl, dtype=torch.float32),\n",
        "#     )\n",
        "# print(torch.stack((X, Y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybadPLmoE4a4"
      },
      "source": [
        "## Renderer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pft_potR-0Ut"
      },
      "source": [
        "Loading PixlNeRF models\n",
        "\n",
        "- The volume renderer is in src/nerf.py\n",
        "- Can easily wrap a net with a renderer using _RenderWrapper function\n",
        "- The current volume renderer samples points in the following way:\n",
        "  - Sample 64 coarse points (uniform sample)\n",
        "  - Sample 16 fine points (importance sample, still need to check how)\n",
        "  - Compute an expected depth, then sample 16 random normal points with sd=0.01 around that depth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "ExobcYT0XFpg",
        "outputId": "d814ab7f-b8ca-4cad-93e7-54b794fb9466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using torchvision resnet34 encoder\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load /Users/yankesong/Documents/YankeSong/Harvard Textbook/MIT 6.S980/Project/checkpoints/srn_car/pixel_nerf_latest\n"
          ]
        }
      ],
      "source": [
        "# Create a custom conf\n",
        "from pyhocon import ConfigFactory\n",
        "conf = ConfigFactory.parse_file(f\"adaptive-volume-rendering/conf/default_mv.conf\")\n",
        "\n",
        "# Create a pixelnerf net\n",
        "net = make_new_model(conf[\"model\"]).to(device=device)\n",
        "net.stop_encoder_grad = True\n",
        "\n",
        "# Load pretrianed weights\n",
        "model_path = f\"{root_dir}checkpoints/srn_car/pixel_nerf_latest\"\n",
        "net.load_weights(model_path)\n",
        "\n",
        "# Combine with volumerenderer\n",
        "renderer = VolumeRenderer.from_conf(conf[\"normal_renderer\"]).to(\n",
        "    device=device\n",
        ")\n",
        "\n",
        "rf_and_renderer = RadFieldAndRenderer(net, renderer).to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: loss = 0.10392\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Step 10: loss = 0.08856\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11\n",
            "12\n",
            "13\n",
            "14\n"
          ]
        }
      ],
      "source": [
        "######## TODO\n",
        "# Test dataset\n",
        "sl = 20\n",
        "dataset = SRNsCars(f'{root_dir}',max_num_instances=1, img_sidelength=sl)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=4)\n",
        "\n",
        "# Configurations\n",
        "optim = torch.optim.Adam(lr=1e-3, params=rf_and_renderer.parameters())\n",
        "\n",
        "try:\n",
        "    _ = fit(net,\n",
        "        rf_and_renderer, \n",
        "        iter(data_loader), \n",
        "        loss_fn=mse_loss, \n",
        "        resolution=(sl, sl, 3), \n",
        "        plotting_function=plot_output_ground_truth, \n",
        "        optimizer=optim, \n",
        "        total_steps=500,\n",
        "        steps_til_summary=10\n",
        "        )\n",
        "except Exception:\n",
        "    print(traceback.format_exc())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
